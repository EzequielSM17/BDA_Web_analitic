{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ingesta de datos (Bronce)\n",
        "Este notebook implementa la **etapa de ingesta** del pipeline Big Data (nivel *Bronce*).\n",
        "El objetivo es:\n",
        "- Leer archivos NDJSON crudos (uno por línea = un evento).\n",
        "- Detectar y aislar líneas rotas o con errores.\n",
        "- Añadir trazabilidad: `_source_file`, `_ingest_ts`, `_batch_id`.\n",
        "- Generar dos DataFrames: uno limpio (`df`) y otro con errores (`bad_df`).\n"
      ],
      "metadata": {
        "id": "6jw3UiYRUv6L"
      },
      "id": "6jw3UiYRUv6L"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pandas as pd\n",
        "from typing import Iterable, List, Tuple\n"
      ],
      "metadata": {
        "id": "Jo3ixRP8UxsT"
      },
      "id": "Jo3ixRP8UxsT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iter_lines(path: str) -> Iterable[str]:\n",
        "    \"\"\"\n",
        "    Itera sobre las líneas de un archivo de texto (NDJSON).\n",
        "    - Verifica que el archivo exista.\n",
        "    - Devuelve cada línea como string.\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(path):\n",
        "        print(f\"[ERROR] No se encontró el fichero: {path}\", file=sys.stderr)\n",
        "        sys.exit(2)\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
        "        for line in fh:\n",
        "            yield line\n"
      ],
      "metadata": {
        "id": "AkoPtJHCUzZz"
      },
      "id": "AkoPtJHCUzZz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación:**\n",
        "\n",
        "Esta función es un generador: devuelve las líneas una por una (sin cargar todo el archivo a memoria).Ideal para archivos grandes (“streaming read”).Si el archivo no existe, se corta el proceso."
      ],
      "metadata": {
        "id": "fvBkC7sxU8fL"
      },
      "id": "fvBkC7sxU8fL"
    },
    {
      "cell_type": "code",
      "source": [
        "def read_ndjson_bronze(path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Lee un archivo NDJSON (un JSON por línea).\n",
        "    Devuelve:\n",
        "      - df: líneas válidas\n",
        "      - bad_df: líneas rotas (no parseables)\n",
        "    \"\"\"\n",
        "\n",
        "    rows: List[dict] = []\n",
        "    bad: List[dict] = []\n",
        "\n",
        "    # Recorre línea a línea\n",
        "    for line in iter_lines(path):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "            obj[\"_source_file\"] = os.path.basename(path)\n",
        "            rows.append(obj)\n",
        "        except Exception:\n",
        "            bad.append({\n",
        "                \"line\": line,\n",
        "                \"_source_file\": os.path.basename(path),\n",
        "                \"_error\": \"invalid_json\"\n",
        "            })\n",
        "\n",
        "    # Crea DataFrames\n",
        "    df = pd.DataFrame(rows)\n",
        "    bad_df = pd.DataFrame(bad)\n",
        "\n",
        "    # Metadata de ingesta\n",
        "    ts_now = pd.Timestamp.now(tz=\"UTC\")\n",
        "    batch_id = os.getpid()\n",
        "\n",
        "    for d in (df, bad_df):\n",
        "        d[\"_ingest_ts\"] = ts_now\n",
        "        d[\"_batch_id\"] = batch_id\n",
        "\n",
        "    return df, bad_df\n"
      ],
      "metadata": {
        "id": "unZ67ehdVKbr"
      },
      "id": "unZ67ehdVKbr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Lee el archivo NDJSON línea por línea.\n",
        "2. Cada línea intenta convertirse en JSON:\n",
        "   - Si es válida → se guarda en `rows`.\n",
        "   - Si falla → se guarda en `bad` con el error `invalid_json`.\n",
        "3. Crea dos DataFrames:\n",
        "   - `df`: los eventos válidos.\n",
        "   - `bad_df`: las líneas rotas.\n",
        "4. Añade columnas de trazabilidad:\n",
        "   - `_source_file`: nombre del archivo de origen.\n",
        "   - `_ingest_ts`: marca de tiempo de ingesta.\n",
        "   - `_batch_id`: identificador único de lote (PID ).\n"
      ],
      "metadata": {
        "id": "A9AlBDE1VNnj"
      },
      "id": "A9AlBDE1VNnj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nivel BRONCE = datos crudos con trazabilidad, mínima transformación.\n",
        "En etapas posteriores (PLATA y ORO) se harán:\n",
        "  - Tipado y normalización de campos.\n",
        "  - Definición de sesiones (timeouts, bots).\n",
        "  - Cálculo de métricas y reportes (embudos, top paths, etc.).\n"
      ],
      "metadata": {
        "id": "sby-bYViVUBj"
      },
      "id": "sby-bYViVUBj"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}