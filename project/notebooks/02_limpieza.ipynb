{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4f32a62c",
      "metadata": {
        "id": "4f32a62c"
      },
      "source": [
        "\n",
        "# ðŸ¥ˆ Etapa **PLATA** Â· Limpieza y NormalizaciÃ³n (Web Logs)\n",
        "\n",
        "Este notebook implementa la fase **PLATA** del pipeline **BRONCE â†’ PLATA â†’ ORO**.\n",
        "\n",
        "**Objetivo:** tomar los eventos crudos (ya ingeridos en BRONCE) y:\n",
        "- **Tipar** correctamente las columnas clave.\n",
        "- **Normalizar** `user_id`, `path`, `referrer`, `device` (consistencia, minÃºsculas, quitar basura).\n",
        "- **Enviar a cuarentena** los registros invÃ¡lidos por campo (con *trazabilidad*).\n",
        "- **Filtrar por dÃ­a objetivo** (`day`) y enviar a cuarentena los fuera de dÃ­a.\n",
        "- **Ordenar y deduplicar** por `[\"user_id\", \"ts\", \"path\"]`.\n",
        "- AÃ±adir columna `date` (string y derivada de `ts`).\n",
        "\n",
        "Al final, devolvemos un `DataFrame` **PLATA** con registros **vÃ¡lidos** y dejamos los **invÃ¡lidos** en ficheros *Parquet* (carpeta de cuarentena).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e61719b",
      "metadata": {
        "id": "3e61719b"
      },
      "source": [
        "\n",
        "## ðŸ“¦ Importaciones\n",
        "Incluimos `pandas` y definimos utilidades de **normalizaciÃ³n** y **escritura Parquet** dentro del propio notebook para que sea autosuficiente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5178ef3",
      "metadata": {
        "id": "c5178ef3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "import pandas as pd\n",
        "\n",
        "# Ajusta si necesitas una carpeta base distinta\n",
        "BASE_DIR = Path('/mnt/data')\n",
        "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e068f08a",
      "metadata": {
        "id": "e068f08a"
      },
      "source": [
        "\n",
        "## ðŸ§° Utilidades de archivos (`utils/files.py` embebido)\n",
        "Estas funciones crean carpetas, aseguran rutas y escriben **Parquet**. En un proyecto real vivirÃ­an en `utils/files.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1187661a",
      "metadata": {
        "id": "1187661a"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "def make_path_dirs(path_dirs: str) -> Path:\n",
        "    # En este notebook resolvemos relativo a BASE_DIR para que sea reproducible\n",
        "    return (BASE_DIR / path_dirs)\n",
        "\n",
        "def ensure_dir(path_dirs: str, file_name: str) -> str:\n",
        "    out_dir = make_path_dirs(path_dirs)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    return str(out_dir / file_name)\n",
        "\n",
        "def write_parquet(df: pd.DataFrame, path_dir: str, file_name: str):\n",
        "    out_path = ensure_dir(path_dir, file_name)\n",
        "    df.to_parquet(out_path, index=False, engine=\"pyarrow\")\n",
        "    return out_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d69579a",
      "metadata": {
        "id": "6d69579a"
      },
      "source": [
        "\n",
        "## ðŸ§½ Utilidades de normalizaciÃ³n (`utils/normalizes.py` embebido)\n",
        "Implementamos las mismas funciones que compartiste para normalizar cadenas, paths, referrers y device.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30034ba6",
      "metadata": {
        "id": "30034ba6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from typing import Any\n",
        "\n",
        "def normalize_string(x: Any) -> str | None:\n",
        "    if not isinstance(x, str):\n",
        "        return None\n",
        "    if x == \"\":\n",
        "        return None\n",
        "    s = x.strip().lower()\n",
        "    return s or None\n",
        "\n",
        "def normalize_string_path(x: Any) -> str | None:\n",
        "    s = normalize_string(x)\n",
        "    if s is None:\n",
        "        return None\n",
        "    s = s.split(\"?\", 1)[0]          # quita querystring\n",
        "    s = re.sub(r\"/{2,}\", \"/\", s)    # colapsa // en /\n",
        "    if s.startswith((\"http://\", \"https://\", \"file://\")):\n",
        "        return None                  # URLs completas no se aceptan como path/referrer\n",
        "    return s or None\n",
        "\n",
        "def normalize_path(x: Any) -> str | None:\n",
        "    s = normalize_string_path(x)\n",
        "    if s and not s.startswith(\"/\"):\n",
        "        s = \"/\" + s\n",
        "    return s or None\n",
        "\n",
        "def normalize_referrer(x: Any) -> str | None:\n",
        "    s = normalize_string_path(x)\n",
        "    if s in {\"\", \"(not set)\"}:\n",
        "        return None\n",
        "    known = {\"direct\", \"google\", \"facebook\"}\n",
        "    if s not in known and s and not s.startswith(\"/\"):\n",
        "        s = \"/\" + s\n",
        "    return s or None\n",
        "\n",
        "def normalize_device(x: Any) -> str | None:\n",
        "    if not isinstance(x, str):\n",
        "        return None\n",
        "    s = x.strip().lower()\n",
        "    return s if s in {\"mobile\", \"desktop\", \"tablet\"} else None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4806907",
      "metadata": {
        "id": "b4806907"
      },
      "source": [
        "\n",
        "## ðŸ¥ˆ FunciÃ³n principal: `to_silver(df, day, quarantine_dir)`\n",
        "- **Entrada:** `df` (DataFrame crudo/bronze), `day` (ej. `\"2025-11-08\"` en UTC), `quarantine_dir` (carpeta para errores).\n",
        "- **Salida:** `DataFrame` validado/normalizado del **dÃ­a objetivo**, sin duplicados.\n",
        "- **Efecto colateral:** escribe ficheros Parquet de **cuarentena** por cada tipo de error encontrado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de72f39b",
      "metadata": {
        "id": "de72f39b"
      },
      "outputs": [],
      "source": [
        "\n",
        "def to_silver(df: pd.DataFrame, day: str, quarantine_dir: str) -> pd.DataFrame:\n",
        "    \"\"\"Limpieza y normalizaciÃ³n; los registros invÃ¡lidos van a cuarentena.\"\"\"\n",
        "    out = df.copy()\n",
        "\n",
        "    # Tipado/normalizaciÃ³n\n",
        "    out[\"ts\"] = pd.to_datetime(out[\"ts\"], errors=\"coerce\", utc=True)\n",
        "    out[\"user_id\"] = out[\"user_id\"].apply(normalize_string).astype(\"string\")\n",
        "    out[\"path\"] = out[\"path\"].apply(normalize_path).astype(\"string\")\n",
        "    out[\"referrer\"] = out[\"referrer\"].apply(normalize_referrer).astype(\"string\")\n",
        "    out[\"device\"] = out[\"device\"].apply(normalize_device).astype(\"string\")\n",
        "\n",
        "    # Enviar a cuarentena registros invÃ¡lidos campo a campo\n",
        "    for key in out.columns:\n",
        "        if key in {\"ts\", \"user_id\", \"path\", \"referrer\", \"device\"}:\n",
        "            mask_errors = out[key].isna()\n",
        "            invalid = out.loc[mask_errors].copy()\n",
        "            out.dropna(subset=[key], inplace=True)\n",
        "            if not invalid.empty:\n",
        "                invalid[\"_error\"] = key if key != \"ts\" else \"ts\"\n",
        "                path_written = write_parquet(invalid, f\"{quarantine_dir}/{day}\", f\"error_{key}.parquet\")\n",
        "                print(f\"[WARN] {len(invalid)} filas invÃ¡lidas enviadas a â†’ {path_written}\")\n",
        "\n",
        "    # Filtrar por dÃ­a objetivo (UTC)\n",
        "    day0 = pd.Timestamp(day, tz=\"UTC\")\n",
        "    mask_day = (out[\"ts\"] >= day0) & (out[\"ts\"] < day0 + pd.Timedelta(days=1))\n",
        "    valid_day = out.loc[mask_day].copy()\n",
        "    invalid_day = out.loc[~mask_day].copy()\n",
        "    if not invalid_day.empty:\n",
        "        invalid_day[\"_error\"] = \"outside_day\"\n",
        "        path_written = write_parquet(invalid_day, f\"{quarantine_dir}/{day}\", \"error_out_ts.parquet\")\n",
        "        print(f\"[WARN] {len(invalid_day)} filas invÃ¡lidas enviadas a â†’ {path_written}\")\n",
        "\n",
        "    # Orden y deduplicaciÃ³n\n",
        "    valid_day = (\n",
        "        valid_day.sort_values([\"user_id\", \"ts\", \"path\"])\n",
        "        .drop_duplicates(subset=[\"user_id\", \"ts\", \"path\"], keep=\"first\")\n",
        "    )\n",
        "\n",
        "    # Columna de fecha (string)\n",
        "    valid_day[\"date\"] = valid_day[\"ts\"].dt.date.astype(\"string\")\n",
        "    return valid_day\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a113bffa",
      "metadata": {
        "id": "a113bffa"
      },
      "source": [
        "\n",
        "### ðŸ” Paso a paso (resumen)\n",
        "\n",
        "1. **Parseo y tipado** de `ts` (UTC) y normalizaciÃ³n de `user_id`, `path`, `referrer`, `device`.\n",
        "2. **Cuarentena por columna:** se detectan `NaN` tras normalizar; esas filas se escriben en Parquet con `_error` especÃ­fico.\n",
        "3. **Filtro por dÃ­a (`day`)** en UTC: lo que no cae en `[day, day+1)` se manda a `error_out_ts.parquet`.\n",
        "4. **Orden y dedupe** por `user_id, ts, path`.\n",
        "5. **`date`**: columna derivada para facilitar agregaciones posteriores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9086ce9c",
      "metadata": {
        "id": "9086ce9c"
      },
      "source": [
        "\n",
        "## ðŸ§ª DemostraciÃ³n mÃ­nima\n",
        "Creamos un pequeÃ±o DataFrame con casos buenos y malos para ver cÃ³mo funciona `to_silver`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65a6b29",
      "metadata": {
        "id": "c65a6b29"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Datos de ejemplo\n",
        "raw = pd.DataFrame([\n",
        "    {\"ts\": \"2025-11-08T10:00:00Z\", \"user_id\": \" U1 \", \"path\": \" / \", \"referrer\": \"Google\",   \"device\": \"Mobile\"},\n",
        "    {\"ts\": \"2025-11-08T10:05:00Z\", \"user_id\": \"u1\",  \"path\": \"/productos\", \"referrer\": \"direct\",   \"device\": \"desktop\"},\n",
        "    {\"ts\": \"2025-11-08T10:05:00Z\", \"user_id\": \"u1\",  \"path\": \"/productos\", \"referrer\": \"direct\",   \"device\": \"desktop\"},  # duplicado exacto\n",
        "    {\"ts\": \"2025-11-08T10:40:00Z\", \"user_id\": \"u2\",  \"path\": \"contacto\",   \"referrer\": \"(not set)\",\"device\": \"tablet\"},\n",
        "    {\"ts\": \"2025-11-09T01:00:00Z\", \"user_id\": \"u3\",  \"path\": \"/carrito\",   \"referrer\": \"facebook\", \"device\": \"MOBILE\"},   # fuera de dÃ­a\n",
        "    {\"ts\": None,                   \"user_id\": \"u4\",  \"path\": \"/x\",         \"referrer\": \"??\",       \"device\": \"unknown\"},  # ts invÃ¡lido, device invÃ¡lido\n",
        "    {\"ts\": \"2025-11-08T12:00:00Z\", \"user_id\": \"\",    \"path\": \"/y?utm=1\",   \"referrer\": \"site.com\", \"device\": \"desktop\"},  # user_id vacÃ­o\n",
        "])\n",
        "\n",
        "day = \"2025-11-08\"\n",
        "quarantine_dir = \"quarantine_plata\"\n",
        "\n",
        "silver = to_silver(raw, day, quarantine_dir)\n",
        "print(\"âœ… Filas vÃ¡lidas (PLATA):\", len(silver))\n",
        "silver\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dce5928",
      "metadata": {
        "id": "4dce5928"
      },
      "source": [
        "\n",
        "### ðŸ“‚ Salidas de cuarentena\n",
        "Los ficheros Parquet con errores se escriben bajo `quarantine_plata/<day>/...` relativo a `BASE_DIR`.\n",
        "\n",
        "Puedes inspeccionarlos con:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8538ef97",
      "metadata": {
        "id": "8538ef97"
      },
      "outputs": [],
      "source": [
        "\n",
        "list((BASE_DIR / quarantine_dir / day).glob(\"*.parquet\"))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}